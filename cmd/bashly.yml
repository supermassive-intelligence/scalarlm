name: scalarlm
help: ScalarLM CLI
version: 0.5.0


commands:

- name: build-image
  help: Build image from dockerfile
  args:
    - name: target
      allowed: ["cpu", "nvidia", "arm", "amd"]
      default: "cpu"
    - name: sm_arch
      help: GPU streaming multiprocessor architecture, e.g. 7.5, 8.0, 8.6, 12.0, auto
      default: "auto"

- name: depot-build
  help: Build image from dockerfile and push to depot
  args:
    - name: target
      allowed: ["cpu", "nvidia", "arm", "amd"]
      default: "cpu"
    - name: sm_arch
      help: GPU streaming multiprocessor architecture, e.g. 7.5, 8.0, 8.6, 12.0, auto
      default: "auto"

- name: up
  help: Start the container
  args:
    - name: target
      allowed: ["cpu", "nvidia", "amd"]
      default: "cpu"
    - name: sm_arch
      allowed: ["7.5", "8.6", "12.0", "auto"]
      help: GPU streaming multiprocessor architecture, e.g. 7.5, 8.0, 8.6, 12.0, auto
      default: "auto"

- name: test
  help: Run tests in the container
  args:
    - name: test-path
      default: "test/infra/*"
      help: Relative path to the directory or file with test cases
  flags:
    - long: --coverage-path
      arg: coverage-path
      help: Absolute path to a directory to write coverage results into
      default: /tmp/cray/coverage
    - long: --verbose
      help: Prints out DEBUG logs as the test is running.
      arg: verbose
      allowed: ["yes", "no"]
      default: "no"

    - long: --workers
      arg: workers
      help: Number of workers, default is auto
      default: "auto"

- name: llm
  help: Invoke the LLM tool

  commands:
    - name: plot
      help: Plot the LLM data
      args:
        - name: model
          help: Model name to plot


    - name: logs
      help: Get the logs for the LLM model
      args:
        - name: model
          help: Model name to get logs for
      flags:
        - long: --tail
          short: -t
          help: Whether to tail the logs
        - long: --follow
          short: -f
          help: Whether to follow the logs
        - long: --lines
          short: -l
          arg: lines
          help: Number of lines to show
          default: "100"


    - name: ls
      help: List all the LLM models

    - name: squeue
      help: Invoke the squeue tool from SLURM

- name: pypi
  help: Publish the client package to pypi

- name: benchmark
  help: Run the benchmark tests
  args:
    - name: target
      allowed: ["cpu", "nvidia", "arm", "amd"]
      default: "cpu"
    - name: visible-gpus
      help: Comma separated list of the IDs of visible gpus
      default: "0"

